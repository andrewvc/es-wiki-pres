<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body {
        font-family: 'Droid Serif';
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
        color: #333;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">
class: center,middle

# Indexing Wikipedia with Elasticsearch

---
class: center,middle

# Objective
Take 14GiB (compressed) of Wikipedia data and make it searchable

---
class: center,middle

# What is Elasticsearch?

---
class: center,middle
# Elasticsearch is a database.
---
class: center,middle
# Elasticsearch is a distributed database.
---
class: center,middle
# Elasticsearch is a distributed database that's good at searching human language.
---
class: center,middle
# Elasticsearch is a distributed database that's good at analytics and searching human language.
---
class: center,middle
# Elasticsearch is a scalable distributed database that's good at analytics and searching human language.
---
class: center,middle
# What You Need to Know
---

# How Elasticsearch Stores Documents

* It stores **documents** in **indexes** on a **node** (usually 1 machine)
* Multiple nodes form a **cluster**
* There are more schema details, but they aren't important for this talk

---
class: center,middle
# YSK: Elasticsearch is Built on Lucene
---
class: center,middle
# Back to Wikipedia
---
class: center,middle
# What We're Going to Build
---

# Desired Search Properties

* Relevance (returned documents should be good matches for the query)
* Speed (queries should return quickly)
* Statistics (we might want some aggregate stats about the Wiki corpus)

---

# Steps

* Read Wikipedia Data
* Coerce Data into a Useful Document Schema
* Load Documents into Database
* Perform a Search

---

# What Data are We Working With?

* Titles
* Redirects (an alias for a title)
* Body Text (plus rich markup)


---

# Here's a sample document we'll match against

```json
{
  "title": "United States",
  "redirects": ["USA", "United States of America"],
  "text": "The United States of America (USA), commonly referred to..."
}
```

---

# How do we Define Success?

* A search for an exact article title turns it up as #1
* A search for something missing a word or two still finds it
* A search for a general idea or related group of words should find the most similar article.

---

# How we Frame the Problem

For search problems we think in terms of **relevance** or **scoring** instead of
**boolean** matching.

```sql
--- Boolean query, does it have either term?
SELECT * FROM users WHERE hobbies LIKE '%basketball%' OR hobbies LIKE '%baseball%'
```

```sql
--- Boolean query with a (poor) rank algorithm
SELECT
username, hobbies
CASE
  WHEN hobbies LIKE '%basketball%'
  THEN 1
  WHEN hobbies LIKE '%baseball%'
  THEN 1
  WHEN hobbies LIKE '%baseball%' AND hobbies LIKE '%basketball%'
  THEN 2
END AS score
FROM users
ORDER BY score DESC
```

---
class: center, middle
# Elasticsearch/Lucene are Built for This
---
# An Easy Question to Ask
*"Find me users named 'Pat', tolerating a misspelling of up to two characters,
 also, make sure these users have 'basketball' listed among their hobbies within
 up to three words of the term 'coach' or 'coaching', or any other 'coach'-like words,
 ranking these results weighted toward how closely their username matches, but also by how frequently
 the text sees 'basketball' and coach around each other. Also, while you're at it,
 give me a histogram of the 5 year age groups these users fall into."*
---
# Phrased for Elasticsearch
```json
{
  "query": {
    "query_string": "username:\"Pat\"~ AND hobbies:\"basketball coach\"~3"
  },
  "aggs": {"ages": {"histogram": {"field": "age", "interval": 5}}}
}
```
---
class: center,middle
# Once Again, Back to Wikipedia...
---

# A Simple Search Algorithm

* If the title or a redirect exactly matches the query make that our #1 result
* If the title is very similar to the query it should be given a very high score
* If the body contains the query with disproportionate frequency that should boost the document's score

---

# The Essence of Our Query

```javascript
// Match the title OR a redirect exactly, give this a mega-boost
title.title_simple:"United States"^10000
OR redirects.redirects_simple:"United States"^10000
// Match the analyzed title or redirects, give this a big boost
OR title.title_snow:"United States"^100
OR redirects.redirects_snow:"United States"^100
// Match the text of the body either with simple analysis or advanced
// If it matches the simpler analysis exactly give it a small boost
OR body.body_simple:"United States"^2
OR body.body_snow:"United States"
```

---

# Here's Our Query

```json
POST /en-wikipedia2/_search
{
  "fields": ["title"],
  "highlight": {
    "fields": {"title": {}, "redirects": {},"body": {}}
  },
  "query": {
    "query_string": {
      "query": "title.title_simple:\"united States\"^10000 OR redirects.redirects_simple:\"united States\"^1000 OR title.title_snow:\"united States\"^10 OR redirects.redirects_snow:\"united States\"^10 OR body.body_simple:\"united States\"^5 OR body.body_snow:\"united States\""
    }
  }
}
```

---

# How This Works

1. Documents are scored by the combined metric in our query
1. The scored documents are then sorted by score
1. Thee top articles are then returned.

---
class: center,middle
# What is that 'Snow' Stuff?
---
# Text Analysis

Analysis is turning a **text** into **tokens**.

<div class="center">
<pre>
'Wonderous "Book of Secrets" finds home in secret books of wonder.'
▼
[SNOWBALL FILTER]
▼
['wonder', 'book', null 'secret', 'find', 'home', null,
 'secret', 'book', 'wonder']
</pre>
</div>
---

# Snowballs and Stemming

![Analysis](img/analysis.png)

Words are reduced to their root

---
class: center, middle
## Why Does this Make Search Fast / Accurate?
---
class: center, middle
## By normalizing text BEFORE search lookup time is reduced.

---

# Analyzers Used Here:

* **Snowball**: This analyzer is great for stemming English words.
* **Simple**: Split the text on whitespace, then lowercase it

**Note:** *Elasticsearch comes with over 20 default analyzers/tokenizers, and more can be installed as plugins.*
---
# Our Query Again

```javascript
// Match the title OR a redirect exactly, give this a mega-boost
title.title_simple:"United States"^10000
OR redirects.redirects_simple:"United States"^10000
// Match the analyzed title or redirects, give this a big boost
OR title.title_snow:"United States"^100
OR redirects.redirects_snow:"United States"^100
// Match the text of the body either with simple analysis or advanced
// If it matches the simpler analysis exactly give it a small boost
OR body.body_simple:"United States"^2
OR body.body_snow:"United States"
```

---
class: center, middle
# Some Fun Tricks

---

# Get the Most Common Words in Titles

```json
GET /en-wikipedia2/_search?search_type=count
{
  "fields": ["title"],
  "aggregations" : {
    "topterms" : {
      "terms" : { "field" : "title.title_simple", "size": 100 }
    }
  }
}
```

---

# Perform a Fast Autocomplete

```json
# Auto-complete suggest
GET en-wikipedia2/_suggest
{
  "page-suggest": {
    "text": "Futuram",
    "completion": {"field": "suggest"}
  }
}
```

---

## Get the United States article's MLT docs

```json
GET en-wikipedia2/_search
{
  "fields": ["title"],
  "query": {
    "more_like_this": {
      "fields": ["title.title_snow", "redirects.redirects_snow", "body.body_snow"],
      "docs": [{
        "_type": "page",
        "_id": "AU5lmkRiwqDJyRWGOM94"
      }]
    }
  }
}
```

---

# Get the United States Environmental Protection Agency article's MLT docs
```json
GET en-wikipedia2/_search
{
  "fields": ["title"],
  "query": {
    "more_like_this": {
      "fields": ["title.title_snow", "redirects.redirects_snow", "body.body_snow"],
      "docs": [{
        "_type": "page",
        "_id": "AU5lhtPiwqDJyRWGLSDt"
      }]
    }
  }
}
```

---

# More Goodies

* Geosearch
* Great for searching and storing log data (Logstash)
* Easily implemented, fast, decaying popularity
* Numeric Processing
* Weighting by popularity or page rank
* Complex multi-level aggregations
* 28 Configurable Aggregation types
* More stuff I forgot to tell you

    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>
